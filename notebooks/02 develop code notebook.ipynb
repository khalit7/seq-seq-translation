{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be696132-e345-4d79-b45a-caa322b3c742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'trainer' from '/Users/khalid/personal_nlp_playground/seq-seq-translation/notebooks/../utils/trainer.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import re \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import BatchSampler,Sampler,SequentialSampler\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "\n",
    "import data_helper\n",
    "import dataset\n",
    "import sampler\n",
    "import models\n",
    "import masked_loss\n",
    "import trainer\n",
    "\n",
    "import itertools\n",
    "from functools import partial\n",
    "\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(data_helper)\n",
    "importlib.reload(sampler)\n",
    "importlib.reload(models)\n",
    "importlib.reload(masked_loss)\n",
    "importlib.reload(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfbce60-b234-498c-bd33-c1e4a6ac5704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a28ccca4-78e1-411f-a131-4a276f83c1b1",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e296cc91-b703-4ee8-a197-1b2095611c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path(\"../dataset/ordered/valid\")\n",
    "ar_path  = dataset_root / \"ar-en.ar\"\n",
    "en_path  = dataset_root / \"ar-en.en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4cc7a2a-7bb9-40dc-87fc-0effbb65143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_tokenizer,ar_tokenizer = dataset._get_tokenizers()\n",
    "\n",
    "# en_itr,ar_itr = data_helper._get_data_itr(en_path,ar_path)\n",
    "\n",
    "# print(\"getting en vocab ... \",end=\" \")\n",
    "# en_vocab = data_helper._build_vocab(en_itr,en_tokenizer)\n",
    "# print(\"Done!\")\n",
    "\n",
    "# print(\"getting ar vocab ... \",end = \" \")\n",
    "# ar_vocab = data_helper._build_vocab(ar_itr,ar_tokenizer)\n",
    "# print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7371768b-6dc4-4809-b38f-cd87f443c5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from txt files ...  Done!\n",
      "building x_vocab ...  Done!\n",
      "building y_vocab ...  Done!\n"
     ]
    }
   ],
   "source": [
    "temp = dataset.en_to_arr_dataset(en_path,ar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "20e7de71-ec70-403b-a88a-fc62611cc91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92670"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "7c028c40-1e28-4bf3-9dac-d97a1f279921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x,y in temp :\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "c793f450-3630-47ae-9ce3-d1699a10d817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "8ecbd840-0ccd-45bb-bcad-17c2ff7f2cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 . at its <unk> meeting on 19 may 2009 , the commission considered and provisionally adopted the following draft guidelines , of which it had taken note at its sixtieth session 2 . 8 . 1 ( <unk> acceptance of reservations ) , 2 . 8 . 2 ( unanimous acceptance of reservations ) , 2 . 8 . 3 ( express acceptance of a reservation ) , 2 . 8 . 4 ( written form of express acceptance ) , 2 . 8 . 5 ( procedure for formulating express acceptance ) , 2 . 8 . 6 ( <unk> of confirmation of an acceptance made prior to formal confirmation of a reservation ) , 2 . 8 . 7 ( acceptance of a reservation to the constituent instrument of an international organization ) , 2 . 8 . 8 ( organ competent to accept a reservation to a constituent instrument ) , 2 . 8 . 9 ( modalities of the acceptance of a reservation to a constituent instrument ) , 2 . 8 . 10 ( acceptance of a reservation to a constituent instrument that has not yet entered into force ) , 2 . 8 . 11 ( reaction by a member of an international organization to a reservation to its constituent instrument ) and 2 . 8 . 12 ( final nature of acceptance of a reservation ) .\n",
      "\n",
      "<SOS> 57- وفي جلستها <unk> المعقودة في 19 أيار/مايو 2009، نظرت اللجنة في مشاريع المبادئ التوجيهية التالية التي أحاطت علماً بها في دورتها الستين ( ) <unk> ( القبول <unk> بالتحفظات ) ، <unk> ( قبول التحفظات بالإجماع ) ، <unk> ( القبول الصريح <unk> ) ، <unk> ( الشكل <unk> <unk> الصريح ) ، <unk> ( إجراءات صوغ القبول الصريح ) ، <unk> ( عدم اشتراط تأكيد القبول الذي يتم قبل تأكيد التحفظ رسمياً ) ، <unk> ( قبول التحفظ على الوثيقة <unk> لمنظمة دولية ) ، <unk> ( الجهاز المختص بقبول التحفظ على وثيقة <unk> ) ، <unk> ( طرائق قبول التحفظ على وثيقة <unk> ) ، <unk> ( قبول التحفظ على وثيقة <unk> لم يبدأ نفاذها بعد ) ، <unk> ( رد فعل العضو في منظمة دولية بشأن تحفظ على الوثيقة <unk> ) ، <unk> ( الطابع النهائي لقبول التحفظ ) ، واعتمدت مشاريع المبادئ التوجيهية هذه مؤقتاً . <EOS>\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(temp.x_vocab.lookup_tokens(x)))\n",
    "print()\n",
    "print(\" \".join(temp.y_vocab.lookup_tokens(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5202c66-f045-41d4-a462-af55f04e3710",
   "metadata": {},
   "source": [
    "# Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9cb58b9b-231f-42d4-9d68-51ff4785a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "drop_last = False\n",
    "s = sampler.RandomSameLengthSampler(temp,num_samples=batch_size)\n",
    "bs = sampler.CustomBatchSampler(s,batch_size,drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "f1e40c49-869c-4b68-a78a-e87bcbf7a657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3014\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x in bs:\n",
    "    counter+=1\n",
    "    # print(x)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "a66b72ad-560c-403a-9bbc-533670198ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = sampler.CustomBatchSampler([1,2,3,4,5,6,7,8,9,10,11],batch_size=5,drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbcc466-ef7e-4a27-85e1-36a2d4e0d089",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "4be45a86-e080-4d6d-956f-08fbddef4fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = torch.zeros(2,4)\n",
    "a2 = torch.zeros(3,4)\n",
    "torch.concat([a1,a2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "9b76c78c-1950-4705-8e1a-0d084311f7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4])"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(a1, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa948cf3-11cc-4aad-b63d-01db437ac37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "1469d257-68d5-4f87-be45-d4648f9a5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(Y,padding_fill_value):\n",
    "    mask = []\n",
    "    \n",
    "    for seq in Y:\n",
    "        seq_mask = []\n",
    "        for token in seq:\n",
    "            if token == padding_fill_value:\n",
    "                seq_mask.append(0)\n",
    "            else:\n",
    "                seq_mask.append(1)\n",
    "        mask.append(seq_mask)\n",
    "        \n",
    "    return mask\n",
    "            \n",
    "def collate_fn(batch,padding_fill_value):\n",
    "    # get X and Y\n",
    "    X = torch.concat( [torch.unsqueeze(torch.tensor(x[0]), 0) for x in batch] ,dim=0 )\n",
    "    Y = torch.tensor(list(itertools.zip_longest(*[ x[1] for x in batch  ], fillvalue=3))).T\n",
    "    # get mask\n",
    "    mask = torch.tensor(get_mask(Y,padding_fill_value))\n",
    "    \n",
    "    return X,Y,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "2864a5bf-3aeb-4458-aae7-65258979825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_fill_value=3\n",
    "dl = torch.utils.data.DataLoader(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "6ad84796-cea1-4d3a-b7b5-787d9f82dcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x,y in dl:\n",
    "    #\n",
    "    break\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "6d2510a7-ffad-4afd-99c1-182fdb626d63",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[402], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "6ac70074-4a2f-4a10-945f-639b6d714332",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[403], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "62118004-e146-45bc-a632-536840a96f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b624443c-7627-4778-a91f-e32ebb407906",
   "metadata": {},
   "source": [
    "# all togather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "ef203272-2a2c-4e51-af88-af767c435143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from txt files ...  Done!\n",
      "building x_vocab ...  Done!\n",
      "building y_vocab ...  Done!\n"
     ]
    }
   ],
   "source": [
    "drop_last=False\n",
    "batch_size=32\n",
    "dl,x_vocab,y_vocab = dataset.get_data_loader(en_path,ar_path,batch_size,drop_last,x_vocab=None,y_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "45cc0626-db70-42dc-91da-e9676734b173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3014\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x in dl.batch_sampler:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "d467f5ec-bab9-454a-8fea-c4e91eba3211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92670\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x in dl.sampler:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "a6c1c0f7-ca17-42d2-b80d-05d0094db694",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92670\n",
      "3014\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "num_of_steps = 0\n",
    "for i,(x,y,mask) in enumerate(dl,1):\n",
    "    # print(x.shape)\n",
    "    if i% 10000 == 0:\n",
    "        print(f\"Finished {i} steps\")\n",
    "    counter+=x.shape[0]\n",
    "    num_of_steps+=1\n",
    "    \n",
    "print(counter)\n",
    "print(num_of_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "793cd965-f36d-46eb-9d06-4c57f2ac21be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3014"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b788d575-8c94-450c-8b7d-3c9f5db290a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57869"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "a16e9b7c-69c5-4a12-acd7-a6ad90d8b72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "bad067b0-628a-4d77-af6e-fbfab452de60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 127])"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "54256184-9db1-4688-9f9e-e7e383595ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 206])"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "1ba903f9-1612-4850-8257-e9fa4afff26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 206])"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6303a51-2a70-430b-87c7-cbe86b7a70fd",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "7360a7b4-ffe6-4274-8372-243a95c04e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seq2seq(\n",
       "  (encoder): Encoder(\n",
       "    (embed): Embedding(27379, 300)\n",
       "    (lstm): LSTM(300, 120, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embed): Embedding(70948, 300)\n",
       "    (lstm): LSTM(300, 120, batch_first=True)\n",
       "    (fc): Linear(in_features=120, out_features=70948, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 935,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.seq2seq(len(x_vocab),len(y_vocab),embed_size=300,hidden_size=120,num_layers=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "ea2e2b24-ba90-4001-b871-054b0db48dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3296, 70948])"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(x,y)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "05c909c0-0f78-452e-ae1a-7659e328a9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 206])"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "14907686-9a2a-4669-8904-68524f563ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3296])"
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.flatten().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181baefc-7706-469b-b41f-e6480f7ad03a",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "faa6b6a5-9ff5-4e1b-b26b-8423a261d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = masked_loss.masked_crossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "c94b446c-c505-4d96-ab2f-689babdc7d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3296])"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "cc263276-d979-4222-ac06-9f32ddce4944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3296, 70948])"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "faa4eddd-a6eb-4960-bc7a-361329f43656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3296])"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ones(y.flatten().shape)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "cc46e354-9bf3-4fca-bb37-0a123fab9951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.3168, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 955,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(output,y.flatten(),mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15053e6-bd32-45cb-a561-3f342d358737",
   "metadata": {},
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "2824723e-7547-4a42-86e5-db87b4d319e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from txt files ...  Done!\n",
      "building x_vocab ...  Done!\n",
      "building y_vocab ...  Done!\n",
      "Reading data from txt files ...  Done!\n",
      "setting previously calculated vocabs ...  Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"seq2seq\"\n",
    "batch_size = 16\n",
    "drop_last = False\n",
    "embed_size = 300\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "\n",
    "# en_path=\n",
    "# ar_path=\n",
    "\n",
    "number_of_epochs = 10\n",
    "criterion = masked_loss.masked_crossEntropyLoss\n",
    "scheduler = None\n",
    "lr = 0.05\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "device = \"cpu\"\n",
    "model_path = f\"../weights/{model_name}\"\n",
    "\n",
    "\n",
    "train_loader,x_vocab, y_vocab = dataset.get_data_loader(en_path,ar_path,batch_size,drop_last,x_vocab=None,y_vocab=None)\n",
    "val_loader,_,_ = dataset.get_data_loader(en_path,ar_path,batch_size,drop_last,x_vocab=x_vocab,y_vocab=y_vocab)\n",
    "\n",
    "model = models.seq2seq(len(x_vocab),len(y_vocab),embed_size=embed_size,hidden_size=hidden_size,num_layers=num_layers)\n",
    "writer = SummaryWriter(f\".runs/{model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "id": "7fe3c440-b1ea-4eec-aded-e949331bfb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "925990"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "892b19a4-fc4d-49a2-acc7-119af01a5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,z in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "f346e58e-d2f6-42db-8b39-15a58218415d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 126])"
      ]
     },
     "execution_count": 913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "60df4447-e27e-4dec-bf89-346dbb654c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainer.Trainer(model,train_loader,val_loader,number_of_epochs,criterion,optimizer,scheduler,device,model_path,model_name,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "aee7cbb3-3b16-45be-b250-7fb4f6ee5346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING STARTED using device = cpu .... training the model seq2seq, the training will continue for 10 epochs\n",
      " \n",
      "    epoch #1\n",
      "        training ... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[920], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/personal_nlp_playground/seq-seq-translation/notebooks/../utils/trainer.py:49\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    epoch #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        training ...\u001b[39m\u001b[38;5;124m\"\u001b[39m,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss_per_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,epoch_loss,e)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDONE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/personal_nlp_playground/seq-seq-translation/notebooks/../utils/trainer.py:88\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     86\u001b[0m print(y_true.shape)\n\u001b[1;32m     87\u001b[0m print(mask.shape)\n\u001b[0;32m---> 88\u001b[0m # get model's predicitions\n\u001b[1;32m     89\u001b[0m y_pred = self.model(x_source,x_target)\n\u001b[1;32m     91\u001b[0m # calculate loss\n",
      "File \u001b[0;32m~/personal_nlp_playground/seq-seq-translation/notebooks/../utils/masked_loss.py:6\u001b[0m, in \u001b[0;36mmasked_crossEntropyLoss\u001b[0;34m(y_pred, y_true, mask)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmasked_crossEntropyLoss\u001b[39m(y_pred,y_true,mask):\n\u001b[1;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     l \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     masked_loss_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(l,mask\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m masked_loss_tensor\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_env/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_env/lib/python3.10/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db20cb-9b9f-40f3-be9b-84392dc8b252",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0814ded8-5df8-4f38-ab4b-694ccba52162",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path(\"../dataset/ordered/train\")\n",
    "ar_path  = dataset_root / \"ar-en.ar\"\n",
    "en_path  = dataset_root / \"ar-en.en\"\n",
    "\n",
    "batch_size = 8\n",
    "drop_last = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7c7b2238-3566-4ffe-8a37-31bfbbcab049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from txt files ...  Done!\n",
      "building x_vocab ...  Done!\n",
      "building y_vocab ...  Done!\n"
     ]
    }
   ],
   "source": [
    "model_name = \"seq2seq\"\n",
    "path = f\"../weights/{model_name}/model.pth\"\n",
    "train_loader,x_vocab, y_vocab = dataset.get_data_loader(en_path,ar_path,batch_size,drop_last,x_vocab=None,y_vocab=None)\n",
    "model = models.seq2seq(len(x_vocab),len(y_vocab),embed_size=300,hidden_size=100,num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e8d5c5dd-405e-48f5-94f2-dd1fa9cd98bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27250"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "570c9050-de4c-4ac6-b971-b05c9f700fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6733555a-9aa0-4496-8d96-d9186fb52620",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get validation loss of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5d848dc-fa29-493d-93a4-e69173bb5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path(\"../dataset/ordered/valid\")\n",
    "ar_path  = dataset_root / \"ar-en.ar\"\n",
    "en_path  = dataset_root / \"ar-en.en\"\n",
    "\n",
    "batch_size = 8\n",
    "drop_last = False\n",
    "device = torch.device(\"cpu\")\n",
    "criterion = masked_loss.masked_crossEntropyLoss\n",
    "val_loader,x_vocab, y_vocab = dataset.get_data_loader(en_path,ar_path,batch_size,drop_last,x_vocab=x_vocab,y_vocab=y_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94959a8b-e4a3-4ec4-9a78-38de65428458",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m         step_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     21\u001b[0m         running_loss\u001b[38;5;241m.\u001b[39mappend(step_loss)\n\u001b[0;32m---> 23\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mmean(running_loss)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "running_loss = []\n",
    "\n",
    "for i,(x_source,y,mask) in enumerate(val_loader,1):\n",
    "    # get x_target and y_true\n",
    "    x_target = y[:,0:-1]\n",
    "    y_true   = y[:,1:].flatten()\n",
    "    # send tensors to device\n",
    "    x_source,x_target,y_true,mask = x_source.to(device),x_target.to(device),y_true.to(device),mask[:,1:].to(device).flatten()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # get model's predicitions\n",
    "        y_pred = model(x_source,x_target)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(y_pred,y_true,mask)\n",
    "\n",
    "        # reigister running loss\n",
    "        step_loss = loss.detach().item()\n",
    "        running_loss.append(step_loss)\n",
    "\n",
    "epoch_loss = np.mean(running_loss)\n",
    "epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da1c89c6-d618-4122-ac70-9a20ab531787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.067629406700863"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bf88e2-3ebd-4b09-9e5f-9c7624592bff",
   "metadata": {},
   "source": [
    "## InferenceDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cfcfa158-5bc8-4082-ac2f-8dfa50861e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embed_size,hidden_size,num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embed = nn.Embedding(self.vocab_size,self.embed_size)\n",
    "        self.lstm = nn.LSTM(input_size=self.embed_size,hidden_size=self.hidden_size,num_layers=self.num_layers,batch_first=True)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x                = self.embed(x)\n",
    "        output,(h_n,c_n) =  self.lstm(x)\n",
    "        \n",
    "        return output,(h_n,c_n)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embed_size,hidden_size,num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embed = nn.Embedding(self.vocab_size,self.embed_size)\n",
    "        self.lstm  = nn.LSTM(input_size=self.embed_size,hidden_size=self.hidden_size,num_layers=self.num_layers,batch_first=True)\n",
    "        self.fc    = nn.Linear(self.hidden_size,self.vocab_size)\n",
    "        \n",
    "    def forward(self,x,h_n,c_n):\n",
    "        x = self.embed(x)\n",
    "        output, (hn, cn) = self.lstm(x,(h_n,c_n))\n",
    "        logits = self.fc(output)\n",
    "        \n",
    "        return logits.reshape(-1,self.vocab_size)\n",
    "    \n",
    "class seq2seq(nn.Module):\n",
    "    \n",
    "    def __init__(self,x_vocab_size,y_vocab_size,embed_size,hidden_size,num_layers):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(x_vocab_size,embed_size,hidden_size,num_layers)\n",
    "        self.decoder = Decoder(y_vocab_size,embed_size,hidden_size,num_layers)\n",
    "        \n",
    "    def forward(self,x_source,x_target):\n",
    "        output,(h_n,c_n) = self.encoder(x_source)\n",
    "        logits           = self.decoder(x_target,h_n,c_n)\n",
    "        \n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c941e2-a03e-4877-a101-8e7b0011c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceSeq2seq(seq2seq):\n",
    "    \n",
    "    def __init__(self,x_vocab_size,y_vocab_size,embed_size,hidden_size,num_layers,y_vocab,k=5):\n",
    "        super().__init__(x_vocab_size,y_vocab_size,embed_size,hidden_size,num_layers)\n",
    "        \n",
    "        self.k = k\n",
    "        self.y_vocab = y_vocab\n",
    "        \n",
    "    def forward(self,x_source):\n",
    "        # encode the input sentence\n",
    "        output,(h_n,c_n) = self.encoder(x_source)\n",
    "        \n",
    "        #\n",
    "        sos_int = torch.tensor(self.y_vocab([\"<SOS>\"])).reshape(1,-1)\n",
    "        top_k_tokens,top_k_probs,(h_n, c_n) = self.get_top_k(sos_int,h_n,c_n)        \n",
    "        top_k_hidden_states = [(h_n,c_n) for _ in range(self.k)]\n",
    "        top_k_paths = [ [x.item()] for x in top_k_tokens ]\n",
    "        \n",
    "        is_done = False\n",
    "        while True:\n",
    "            # initialize beam search variables\n",
    "            k_times_k_tokens = []\n",
    "            k_times_k_probs = []\n",
    "            for i,token in enumerate(top_k_tokens):\n",
    "                if self.y_vocab.lookup_token(token.item()) == \"<EOS>\":\n",
    "                    is_done = True\n",
    "                    continue\n",
    "                token = token.reshape(1,-1)\n",
    "                h_n,c_n = top_k_hidden_states[i]\n",
    "                # get best k tokens and one (h_n,c_n)\n",
    "                tokens,probs,(h_n,c_n) = self.get_top_k(token,h_n,c_n)\n",
    "                k_times_k_tokens.append(tokens)\n",
    "                k_times_k_probs.append(probs)\n",
    "                top_k_hidden_states[i] = (h_n,c_n)\n",
    "                \n",
    "            if is_done:\n",
    "                break\n",
    "            k_times_k_tokens = torch.vstack(k_times_k_tokens)\n",
    "            k_times_k_probs = torch.vstack(k_times_k_probs)\n",
    "\n",
    "\n",
    "            # aggregate results so that u have best k path so far\n",
    "            top_k_probs,top_k_tokens,top_k_hidden_states,top_k_paths = self.beam_step(top_k_probs,k_times_k_probs,top_k_tokens,k_times_k_tokens,top_k_hidden_states,top_k_paths)\n",
    "        \n",
    "        \n",
    "        return top_k_paths,top_k_probs\n",
    "        \n",
    "    \n",
    "    def get_top_k(self,token,h_n,c_n):\n",
    "        # \n",
    "        x = self.decoder.embed(token)\n",
    "        output, (h_n, c_n)  = self.decoder.lstm(x,(h_n,c_n))\n",
    "        logits = self.decoder.fc(output).flatten()\n",
    "        probs = torch.softmax(logits,dim=0)\n",
    "        ## pick top k tokens\n",
    "        top_k = torch.topk(probs,k=self.k)\n",
    "        top_k_tokens = top_k.indices\n",
    "        top_k_probs = torch.log(top_k.values)\n",
    "        \n",
    "        return top_k_tokens,top_k_probs,(h_n, c_n)\n",
    "    \n",
    "    def beam_step(self,top_k_probs,k_times_k_probs,top_k_tokens,k_times_k_tokens,top_k_hidden_states,top_k_paths):\n",
    "        \n",
    "        # get accumulative prob\n",
    "        for i in range(k_times_k_probs.shape[0]):\n",
    "            k_times_k_probs[i] = k_times_k_probs[i] + top_k_probs[i]\n",
    "            \n",
    "        # get top k probs from k_times_k_probs\n",
    "        top_k_probs_object = torch.topk(k_times_k_probs.flatten(),k=self.k)\n",
    "        new_top_k_probs = top_k_probs_object.values\n",
    "        prev_index , curr_index = top_k_probs_object.indices // self.k , top_k_probs_object.indices % self.k\n",
    "        # get top k tokens from prev_index, curr_index \n",
    "        new_top_k_tokens = k_times_k_tokens[prev_index,curr_index]\n",
    "        # get hidden states associated with new_top_k_tokens\n",
    "        new_top_k_hidden_states = [0] * len(top_k_hidden_states)\n",
    "        for i,idx in enumerate(prev_index):\n",
    "            new_top_k_hidden_states[i] = top_k_hidden_states[idx]\n",
    "        \n",
    "        # update top_k_paths\n",
    "        new_top_k_paths = [0]*len(top_k_paths)\n",
    "        for i,idx in enumerate(prev_index):\n",
    "            new_top_k_paths[i] = top_k_paths[idx] + [k_times_k_tokens[idx][curr_index[i]].item()]\n",
    "        \n",
    "            \n",
    "        \n",
    "        return new_top_k_probs,new_top_k_tokens,new_top_k_hidden_states,new_top_k_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "id": "72698dcc-fb60-4f1f-afd9-2cf550cbf5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self,token,prob,h_n,c_n,prev):\n",
    "        self.token = token\n",
    "        self.prob = prob\n",
    "        self.h_n = h_n\n",
    "        self.c_n = c_n\n",
    "        self.prev = prev\n",
    "        \n",
    "        if self.prev is not None:\n",
    "            self.acc_prob = self.prob + self.prev.acc_prob\n",
    "        else:\n",
    "            self.acc_prob = self.prob\n",
    "            \n",
    "        self.acc_prob_per_token = self.calculate_acc_prob_per_token()\n",
    "            \n",
    "    def calculate_acc_prob_per_token(self):\n",
    "        counter = 1\n",
    "        prev_node = self.prev\n",
    "        while prev_node is not None:\n",
    "            counter+=1\n",
    "            prev_node = prev_node.prev\n",
    "            \n",
    "        return self.acc_prob/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "id": "e87f0e86-76f6-4671-83c2-9522b52525c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceSeq2seq(seq2seq):\n",
    "    \n",
    "    def __init__(self,x_vocab_size,y_vocab_size,embed_size,hidden_size,num_layers,y_vocab,k=5):\n",
    "        super().__init__(x_vocab_size,y_vocab_size,embed_size,hidden_size,num_layers)\n",
    "        \n",
    "        self.k = k\n",
    "        self.y_vocab = y_vocab\n",
    "        \n",
    "    def forward(self,x_source):\n",
    "        # encode the input sentence\n",
    "        output,(h_n,c_n) = self.encoder(x_source)\n",
    "        \n",
    "        #\n",
    "        sos_int = torch.tensor(self.y_vocab([\"<SOS>\"])).reshape(1,-1)\n",
    "        sos_node = Node(token=sos_int,prob=0,h_n=h_n,c_n=c_n,prev=None)\n",
    "        \n",
    "        top_k_nodes = self.get_top_k(sos_node)   \n",
    "        \n",
    "        candidate_nodes = []\n",
    "        while len(candidate_nodes) < self.k:\n",
    "            # initialize beam search variables\n",
    "            k_times_k_nodes = []\n",
    "            for i,node in enumerate(top_k_nodes):\n",
    "                if self.y_vocab.lookup_token(node.token.flatten().item()) == \"<EOS>\":\n",
    "                    candidate_nodes.append(node)\n",
    "                    continue\n",
    "                curr_top_k_nodes = self.get_top_k(node)\n",
    "                k_times_k_nodes.extend(curr_top_k_nodes)\n",
    "\n",
    "            # aggregate results so that u have best k nodes so far\n",
    "            top_k_nodes = self.beam_step(k_times_k_nodes)\n",
    "        \n",
    "        return sorted(candidate_nodes,key = lambda x:x.acc_prob,reverse=True)\n",
    "        \n",
    "    \n",
    "    def get_top_k(self,node):\n",
    "        # \n",
    "        token,h_n,c_n = node.token,node.h_n,node.c_n\n",
    "        \n",
    "        x = self.decoder.embed(token)\n",
    "        output, (h_n, c_n)  = self.decoder.lstm(x,(h_n,c_n))\n",
    "        logits = self.decoder.fc(output).flatten()\n",
    "        probs = torch.softmax(logits,dim=0)\n",
    "        ## pick top k tokens\n",
    "        top_k = torch.topk(probs,k=self.k)\n",
    "        top_k_tokens = top_k.indices\n",
    "        top_k_probs = torch.log(top_k.values)\n",
    "        \n",
    "        top_k_nodes = []\n",
    "        for i in range(self.k):\n",
    "            curr_node =  Node(token=top_k_tokens[i].reshape(1,-1),prob=top_k_probs[i],h_n=h_n,c_n=c_n,prev=node)\n",
    "            top_k_nodes.append(curr_node)\n",
    "        return top_k_nodes\n",
    "    \n",
    "    def beam_step(self,k_times_k_nodes):\n",
    "        return sorted(k_times_k_nodes,key = lambda x:x.acc_prob,reverse=True)[0:self.k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "id": "1964cfeb-0b67-4a0c-ba1d-a8c08bf0f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_root = Path(\"../dataset/ordered/train\")\n",
    "# ar_path  = dataset_root / \"ar-en.ar\"\n",
    "# en_path  = dataset_root / \"ar-en.en\"\n",
    "\n",
    "# batch_size = 8\n",
    "# drop_last = False\n",
    "# device = torch.device(\"cpu\")\n",
    "# criterion = masked_loss.masked_crossEntropyLoss\n",
    "# train_loader,x_vocab, y_vocab = dataset.get_data_loader(en_path,ar_path,batch_size,drop_last,x_vocab=None,y_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "id": "e6bce857-a003-4a4f-a943-7c31048b6cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InferenceModel =  InferenceSeq2seq(len(x_vocab),len(y_vocab),embed_size=300,hidden_size=100,num_layers=1,y_vocab=y_vocab,k=5)\n",
    "InferenceModel.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "id": "daadfccc-fb8d-4753-99f6-0db2956d5b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the greenhouse gas emissions by sources and removals by sinks resulting from additional human induced land use , land-use change and forestry activities may be used to meet the commitments under subparagraph ( a ) above of each party included in annex i , provided that these activities have taken place since 1990 .'"
      ]
     },
     "execution_count": 1088,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for input_ in train_loader:\n",
    "#     break\n",
    "# example_input = input_[0][0].reshape(1,-1)\n",
    "# \" \".join(x_vocab.lookup_tokens(input_[0][0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40fe057-fdef-4d63-a77a-5057b91962b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "'the greenhouse gas emissions by sources and removals by sinks resulting from additional human induced land use , land-use change and forestry activities may be used to meet the commitments under subparagraph ( a ) above of each party included in annex i , provided that these activities have taken place since 1990 .\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "id": "2df621f9-0c90-4e83-8ac7-6d12f16d3adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    t = InferenceModel(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "id": "539b0fe1-6e0a-45a9-a718-c54b2bffe11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<EOS> . <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> البرامج هذه أن المتوقع ومن <SOS>'"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = t[0]\n",
    "tokens = []\n",
    "while node is not None:\n",
    "    tokens.append(node.token.flatten().item())\n",
    "    node = node.prev\n",
    "\" \".join(y_vocab.lookup_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5884eeb1-65ee-4184-bfbe-0acda53d824a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_env]",
   "language": "python",
   "name": "conda-env-nlp_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
